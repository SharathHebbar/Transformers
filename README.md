# Transformers (Attention is all you need)

![Context](https://github.com/SharathHebbar/Transformers/blob/main/assets/attention_is_all_you_need.png)

## Articles

- Reference: [Transformers-An Intuition](https://medium.com/@sharathhebbar24/transformers-an-intution-3ef6ef3b15f5)
- Reference: [Text Generation v/s Text2Text Generation](https://medium.com/@sharathhebbar24/text-generation-v-s-text2text-generation-3a2b235ac19b)

## Repository Contents

### Types

1. [Encoder Only Models](https://github.com/SharathHebbar/Transformers/tree/main/Encoder)
2. [Decoder Only Models](https://github.com/SharathHebbar/Transformers/tree/main/Decoder)
3. [Encoder-Decoder Models](https://github.com/SharathHebbar/Transformers/tree/main/Encoder-decoder)

### Codes
1. [Tokenizer](https://github.com/SharathHebbar/Transformers/blob/main/Basics/1.%20Tokenizer.ipynb)
2. [Word Embedding](https://github.com/SharathHebbar/Transformers/blob/main/Basics/2.%20Word_Embeddings.ipynb)
3. [Semantic Search](https://github.com/SharathHebbar/Transformers/blob/main/Basics/3.%20Semantic_Search_Index.ipynb)
4. [Tokenization Positional_Encoding Self Attention](https://github.com/SharathHebbar/Transformers/blob/main/Basics/4.%20Tokenization%2C%20Positional_Encoding%20and%20self_attention.ipynb)
5. [Extractive QnA with BERT](https://github.com/SharathHebbar/Transformers/blob/main/Basics/5_Extractive_QnA_using_BERT.ipynb)
6. [Instruction following using GPT](https://github.com/SharathHebbar/Transformers/blob/main/Basics/6_Instruction_following_using_GPT.ipynb)
7. [Product Review using T5](https://github.com/SharathHebbar/Transformers/blob/main/Basics/7.%20T5_for_product_reviews.ipynb)
8. [Decoder Only Model](https://github.com/SharathHebbar/Transformers/blob/main/Decoder/text-generation.ipynb)
9. [Fill-Mask Encoder Only Model](https://github.com/SharathHebbar/Transformers/blob/main/Encoder/fill-mask.ipynb)
10. [Sentiment Analysis Encoder Only Model](https://github.com/SharathHebbar/Transformers/blob/main/Encoder/sentiment-analysis.ipynb)
11. [Encoder-Decoder Model](https://github.com/SharathHebbar/Transformers/blob/main/Encoder-decoder/text2text-generation.ipynb)

### Theory Stuffs
1. [Hand-written Notes](https://github.com/SharathHebbar/Transformers/tree/main/assets/Notes)
2. [Hyperparameters](https://github.com/SharathHebbar/Transformers/blob/main/config/README.md)
3. [Basics](https://github.com/SharathHebbar/Transformers/tree/main/Basics)
4. [Attention is all you need from scratch](https://github.com/SharathHebbar/Transformers/tree/main/Attention-is-all-you-need) *WIP